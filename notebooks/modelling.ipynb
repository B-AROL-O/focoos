{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_registry import ModelRegistry\n",
    "\n",
    "registry = ModelRegistry()\n",
    "print(registry.list_models())\n",
    "\n",
    "\n",
    "model_info = registry.get_model_info(\"fai-detr-l-obj365\")\n",
    "\n",
    "model_info.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task\n",
    "\n",
    "task = Task.DETECTION\n",
    "layout = DatasetLayout.ROBOFLOW_COCO\n",
    "auto_dataset = AutoDataset(dataset_name=\"aquarium\", task=task, layout=layout, datasets_dir=\"../datasets\")\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-m-coco\", num_classes=train_dataset.dataset.metadata.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with a dataset downloaded from HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import FocoosHUB\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "focoos = FocoosHUB()\n",
    "my_datasets = focoos.list_remote_datasets(include_shared=False)\n",
    "remote_dataset = focoos.get_remote_dataset(my_datasets[0].ref)\n",
    "dataset_path = remote_dataset.download_data()\n",
    "auto_dataset = AutoDataset(dataset_name=dataset_path, task=remote_dataset.task, layout=remote_dataset.layout)\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(remote_dataset.task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-m-coco\", num_classes=train_dataset.dataset.metadata.num_classes)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "infer = model.export(format=\"torchscript\")\n",
    "infer.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.ports import TrainerArgs\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"aquarium2\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=300,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.test(args, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model for inference\n",
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.models.fai_detr.processor import DETRProcessor\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "task = Task.DETECTION\n",
    "layout = DatasetLayout.ROBOFLOW_COCO\n",
    "auto_dataset = AutoDataset(dataset_name=\"aquarium\", task=task, layout=layout, datasets_dir=\"../datasets\")\n",
    "resolution = 640\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, resolution, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-m-coco\", num_classes=train_dataset.dataset.metadata.num_classes)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "postprocessor = DETRProcessor(model.model_info.config)\n",
    "outputs = postprocessor.postprocess(model(image), image)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model for inference\n",
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ConfigManager, ModelManager\n",
    "from focoos.nn.backbone.resnet import ResnetConfig\n",
    "from focoos.ports import (\n",
    "    DatasetLayout,\n",
    "    DatasetSplitType,\n",
    "    ModelFamily,\n",
    "    ModelInfo,\n",
    "    Task,\n",
    "    TrainerArgs,\n",
    ")\n",
    "\n",
    "task = Task.CLASSIFICATION\n",
    "layout = DatasetLayout.CLS_FOLDER\n",
    "auto_dataset = AutoDataset(dataset_name=\"hymenoptera\", task=task, layout=layout, datasets_dir=\"../datasets\")\n",
    "resolution = 224\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, resolution, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "\n",
    "# Create a configuration with a ResNet backbone\n",
    "cls_config = ConfigManager.from_dict(\n",
    "    ModelFamily.IMAGE_CLASSIFIER,\n",
    "    {\n",
    "        \"backbone_config\": dict(ResnetConfig(model_type=\"resnet\", depth=50, pretrained=True)),\n",
    "        \"num_classes\": valid_dataset.dataset.metadata.num_classes,\n",
    "        \"resolution\": resolution,\n",
    "        \"hidden_dim\": 512,\n",
    "        \"dropout_rate\": 0.2,\n",
    "    },\n",
    ")\n",
    "\n",
    "model_info = ModelInfo(\n",
    "    name=\"fai-cls-resnet50\",\n",
    "    description=\"ResNet50 model for classification\",\n",
    "    task=Task.CLASSIFICATION,\n",
    "    classes=[\"cat\", \"dog\", \"bird\"],\n",
    "    im_size=224,\n",
    "    model_family=ModelFamily.CLS,\n",
    "    config=cls_config,\n",
    ")\n",
    "# Create the model\n",
    "model = ModelManager.get(name=model_info.name, model_info=model_info)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "outputs = model(image)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.models.fai_mf.processor import MaskFormerProcessor\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "task = Task.SEMSEG\n",
    "layout = DatasetLayout.ROBOFLOW_SEG\n",
    "auto_dataset = AutoDataset(dataset_name=\"pizza\", task=task, layout=layout, datasets_dir=\"../datasets\")\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "model = ModelManager.get(\n",
    "    \"fai-mf-m-ade\"  # , num_classes=valid_dataset.dataset.metadata.num_classes\n",
    ")\n",
    "\n",
    "postprocessor = MaskFormerProcessor(config=model.model_info.config)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "# model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "outputs = postprocessor.postprocess(\n",
    "    model(image),\n",
    "    image,\n",
    "    predict_all_pixels=True,\n",
    "    use_mask_score=False,\n",
    "    filter_empty_masks=False,\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "# print(outputs.logits.shape,outputs.masks.shape)\n",
    "for det in outputs[0].detections:\n",
    "    print(det.cls_id, det.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.models.fai_mf.processor import MaskFormerProcessor\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "task = Task.INSTANCE_SEGMENTATION\n",
    "layout = DatasetLayout.ROBOFLOW_COCO\n",
    "auto_dataset = AutoDataset(dataset_name=\"fruits\", task=task, layout=layout, datasets_dir=\"../datasets\")\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "model = ModelManager.get(\n",
    "    \"fai-mf-s-coco-ins\"  # , num_classes=valid_dataset.dataset.metadata.num_classes\n",
    ")\n",
    "postprocessor = MaskFormerProcessor(model.config)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "# model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "outputs = postprocessor.postprocess(model(image), image, use_mask_score=False, filter_empty_masks=True, threshold=0.5)\n",
    "\n",
    "# print(outputs.logits.shape,outputs.masks.shape)\n",
    "for det in outputs[0].detections:\n",
    "    print(det.cls_id, det.bbox, det.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.utils.system import get_system_info\n",
    "\n",
    "get_system_info().pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_registry import ModelRegistry\n",
    "\n",
    "registry = ModelRegistry()\n",
    "print(registry.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-l-obj365\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.model_registry import ModelRegistry\n",
    "\n",
    "registry = ModelRegistry()\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "\n",
    "\n",
    "# model_name = \"fai-detr-n-coco\"\n",
    "print(\"=============ONNX=============\")\n",
    "for model_name in [\"bisenetformer-m-ade\"]:\n",
    "    model = ModelManager.get(model_name)\n",
    "    infer = model.export(format=\"onnx\", overwrite=True)\n",
    "    detections, preview = infer.infer(image, annotate=True)\n",
    "    print(detections)\n",
    "Image.fromarray(preview)\n",
    "\n",
    "# print(\"=============TORCHSCRIPT=============\")\n",
    "# for model_name in registry.list_models():\n",
    "#     model = ModelManager.get(model_name)\n",
    "#     infer = model.export(format=\"torchscript\", overwrite=True)\n",
    "#     detections, preview = infer.infer(image, annotate=True)\n",
    "#     print(detections)\n",
    "#     Image.fromarray(preview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
