{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Datasets from external sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install dataset-tools roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from Dataset-Ninja (supervisely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_tools as dtools\n",
    "\n",
    "dtools.download(dataset=\"dacl10k\", dst_dir=\"./datasets/dataset-ninja/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from Roboflow Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=os.getenv(\"ROBOFLOW_API_KEY\"))\n",
    "project = rf.workspace(\"roboflow-58fyf\").project(\"rock-paper-scissors-sxsw\")\n",
    "version = project.version(14)\n",
    "dataset = version.download(\"coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêç Setup Focoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'focoos @ git+https://github.com/FocoosAI/focoos.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install -e ..[cpu] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focoos Cloud Dataset Management\n",
    "\n",
    "This section covers the steps to see the datasets available on the FocoosAI platform and the creation of user datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import Focoos\n",
    "\n",
    "focoos = Focoos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of shared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import Focoos\n",
    "\n",
    "focoos = Focoos()\n",
    "datasets = focoos.list_shared_datasets()\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Name: {dataset.name}\")\n",
    "    print(f\"Reference: {dataset.ref}\")\n",
    "    print(f\"Task: {dataset.task}\")\n",
    "    print(f\"Description: {dataset.description}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import Focoos\n",
    "\n",
    "focoos = Focoos(api_key=os.getenv(\"FOCOOS_API_KEY\"))\n",
    "\n",
    "datasets = focoos.list_datasets(include_shared=False)\n",
    "for dataset in datasets:\n",
    "    print(f\"Name: {dataset.name}\")\n",
    "    print(f\"Reference: {dataset.ref}\")\n",
    "    print(f\"Task: {dataset.task}\")\n",
    "    print(f\"Description: {dataset.description}\")\n",
    "    print(f\"spec: {dataset.spec}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import Focoos\n",
    "\n",
    "focoos = Focoos(api_key=os.getenv(\"FOCOOS_API_KEY\"))\n",
    "\n",
    "datasets = focoos.list_datasets(include_shared=False)\n",
    "refs = [ds.ref for ds in datasets]\n",
    "for ref in refs:\n",
    "    ds = focoos.get_remote_dataset(ref)\n",
    "    ds.delete_remote_data()\n",
    "    ds.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focoos.get_user_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and upload a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import DatasetLayout, Focoos, FocoosTask\n",
    "\n",
    "focoos = Focoos()\n",
    "\n",
    "ds = focoos.add_remote_dataset(\n",
    "    name=\"aeroscapes\", description=\"AeroScapes\", layout=DatasetLayout.SUPERVISELY, task=FocoosTask.SEMSEG\n",
    ")\n",
    "ds_spec = ds.upload_data(\"./datasets/dataset-ninja/aeroscapes1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import DatasetLayout, Focoos, FocoosTask\n",
    "\n",
    "focoos = Focoos()\n",
    "\n",
    "ds = focoos.add_remote_dataset(\n",
    "    name=\"ballons\", description=\"Ballons\", layout=DatasetLayout.ROBOFLOW_SEG, task=FocoosTask.SEMSEG\n",
    ")\n",
    "ds_spec = ds.upload_data(\"./.data/balloons-roboflow-sem.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import Focoos\n",
    "\n",
    "focoos = Focoos()\n",
    "_datasets = focoos.list_datasets(include_shared=False)\n",
    "ds = focoos.get_remote_dataset(_datasets[0].ref)\n",
    "dataset_path = ds.download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.data.datasets.dict_dataset import DictDataset\n",
    "from focoos.data.datasets.map_dataset import MapDataset\n",
    "from focoos.data.mappers.classification_dataset_mapper import ClassificationDatasetMapper\n",
    "from focoos.ports import DatasetSplitType\n",
    "\n",
    "train_dataset = DictDataset.from_folder(\"../datasets/hymenoptera_data\", split=DatasetSplitType.TRAIN)\n",
    "\n",
    "val_dataset = DictDataset.from_folder(\"../datasets/hymenoptera_data\", split=DatasetSplitType.VAL)\n",
    "\n",
    "print(f\"Loaded training dataset with {len(train_dataset)} images\")\n",
    "print(f\"Loaded validation dataset with {len(val_dataset)} images\")\n",
    "print(f\"Classes: {train_dataset.metadata.thing_classes}\")\n",
    "\n",
    "# Create the dataset mappers with augmentations\n",
    "train_mapper = ClassificationDatasetMapper(\n",
    "    is_train=True,\n",
    "    augmentations=[],\n",
    ")\n",
    "\n",
    "val_mapper = ClassificationDatasetMapper(\n",
    "    is_train=False,\n",
    "    augmentations=[],\n",
    ")\n",
    "\n",
    "train_map = MapDataset(mapper=train_mapper, dataset=train_dataset)\n",
    "val_map = MapDataset(mapper=val_mapper, dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "idx = random.randint(0, len(train_map))\n",
    "display(Image.fromarray(train_map[idx].image.numpy().transpose(1, 2, 0)))\n",
    "print(train_map[idx].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
