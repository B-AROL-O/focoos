{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• How to use SOTA Focoos Computer Vision Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêç Setup Focoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'focoos @ git+https://github.com/FocoosAI/focoos.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® There are three ways to use a model:\n",
    "\n",
    "\n",
    "1. Use the model directly in PyTorch for full flexibility using `ModelManager`.\n",
    "2. Deploy the model in production with an optimized export for your preferred inference runtime.\n",
    "3. Effortlessly run your model on Focoos cloud using the `FocoosHUB` and `RemoteModel` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Torch Inference\n",
    "\n",
    "This section demonstrates how to perform local inference using a plain Pytorch model.\n",
    "We will load a model and then run inference on a sample image.\n",
    "\n",
    "First, let's get a model. We need to use the `ModelManager` that will take care of instaciating the right model starting from a pre-trained models, a model ref or a folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import ModelManager\n",
    "\n",
    "model_ref = \"fai-detr-l-obj365\"  # use any of your models here\n",
    "\n",
    "model = ModelManager.get(model_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now run the model by simply passing it an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "im_path = \"https://public.focoos.ai/samples/pexels-abby-chung.jpg\"\n",
    "\n",
    "detections = model.infer(im_path, annotate=True)  # annotate=True will return an annotated image with the detections\n",
    "pprint(detections)\n",
    "Image.fromarray(detections.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How fast is this model locally? We can compute it's speed by using the benchmark utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.benchmark(iterations=10, size=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî® Optimized Inference\n",
    "\n",
    "As you can see, using the torch model is great, but we can achieve better performance by exporting and running it with a optimized runtime, such as Torchscript, TensorRT, CoreML or the ones available on ONNXRuntime.\n",
    "\n",
    "In the following cells, we will export the previous model for one of these and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchscript\n",
    "\n",
    "We already provide multiple inference runtime, that you can see on the `RuntimeTypes` enum. Let's select Torchscript as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to export the model. We can use the export method of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import ModelManager, RuntimeType\n",
    "\n",
    "model_ref = \"fai-detr-l-obj365\"  # use any of your models here\n",
    "\n",
    "model = ModelManager.get(model_ref)\n",
    "runtime = RuntimeType.TORCHSCRIPT_32  # use any of the supported runtimes\n",
    "optimized_model = model.export(runtime_type=runtime, image_size=640, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the output. As you will see, there are not differences from the model in pure torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im_path = \"https://public.focoos.ai/samples/pexels-abby-chung.jpg\"\n",
    "detections = optimized_model.infer(im_path, annotate=True)\n",
    "Image.fromarray(detections.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, let's see its latency with a benchmark! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model.benchmark(iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That's a lot faster! And without losing a bit in performance!\n",
    "\n",
    "You can also try different runtimes. Please note that you need to install the relative packages for onnx and tensorRT for using them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import RuntimeType\n",
    "\n",
    "runtime = RuntimeType.ONNX_CUDA32\n",
    "optimized_model = model.export(runtime_type=runtime)\n",
    "im_path = \"https://public.focoos.ai/samples/pexels-abby-chung.jpg\"\n",
    "detections = optimized_model.infer(im_path, annotate=True)\n",
    "Image.fromarray(detections.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ ONNX with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import RuntimeType\n",
    "\n",
    "runtime = RuntimeType.ONNX_TRT16\n",
    "optimized_model = model.export(runtime_type=runtime)\n",
    "\n",
    "detections = optimized_model.infer(im_path, annotate=True)\n",
    "Image.fromarray(detections.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ‚òÅ FocoosHUB and Remote Inference\n",
    "To use the remote inference feature, you need a Focoos API key.\n",
    "Sign up at https://app.focoos.ai/ and find your personal API key on your profile page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import FocoosHUB\n",
    "\n",
    "FOCOOS_API_KEY = os.getenv(\n",
    "    \"FOCOOS_API_KEY\"\n",
    ")  # write here your API key, otherwise it will be loaded automatically from env vars\n",
    "hub = FocoosHUB(api_key=FOCOOS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üì¶ See your models on HUB\n",
    "You can see the models available for you on the platform with an intuitive user interface.\n",
    "However, you can also list them using the Hub functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(hub.list_remote_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üåç Remote Inference\n",
    "\n",
    "In this section, you'll run a model on the Focoos' servers instead of on your machine. The image will be packed and sent on the network to the servers, where it is processed and the results is retured to your machine, all in few milliseconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = \"fai-detr-l-obj365\"  # use any of your models here\n",
    "\n",
    "remote_model = hub.get_remote_model(model_ref)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Using the model is as simple as it could! Just call it with an image,\n",
    "you can use local image path or remote path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im_path = \"https://public.focoos.ai/samples/pexels-abby-chung.jpg\"\n",
    "\n",
    "detections = remote_model.infer(\n",
    "    im_path, annotate=True\n",
    ")  # annotate=True will return an annotated image with the detections\n",
    "\n",
    "pprint(detections)\n",
    "\n",
    "Image.fromarray(detections.image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
